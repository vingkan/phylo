{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import phylo as ph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object): \n",
    "    \n",
    "    def __init__(self): \n",
    "        self.shape = ph.M ** 2 \n",
    "        self.discriminator = None # Discriminator \n",
    "        self.generator = None # Shareholder value generator\n",
    "        self.adversary_model = None # Adversarial Model \n",
    "        self.discriminator_model = None # Discriminator Model \n",
    "    \n",
    "    def discriminate(self): \n",
    "        '''\n",
    "        Discriminator that transforms 96*96 flat list to a source of truth \n",
    "        '''\n",
    "        if self.discriminator: \n",
    "            return self.discriminator\n",
    "        \n",
    "        self.discriminator = Sequential() \n",
    "        depth = 64 \n",
    "        dropout = 0.4 \n",
    "        channel = 1\n",
    "        \n",
    "        dim = int(self.shape ** .5)\n",
    "        \n",
    "        # In: 96*96 flat list \n",
    "        # Out: 96 x 96 x 1 \n",
    "        self.discriminator.add(Dense(dim*dim*channel, input_dim=self.shape))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        # In: dim*dim*channel \n",
    "        # Out: 48 x 48 x 1, depth = 64\n",
    "        self.discriminator.add(Conv2D(depth*1, 5, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        self.discriminator.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        self.discriminator.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        self.discriminator.add(Conv2D(depth*8, 5, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        self.discriminator.add(Conv2D(depth*16, 5, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        self.discriminator.add(Conv2D(depth*32, 5, strides=1, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        # Flatten back out \n",
    "        self.discriminator.add(Flatten())\n",
    "        self.discriminator.add(Dense(1))\n",
    "        self.discriminator.add(Activation('sigmoid'))\n",
    "        self.discriminator.summary()\n",
    "        return self.discriminator\n",
    "\n",
    "    def generate(self): \n",
    "        '''\n",
    "        Generator that takes random noise and produces an image from it \n",
    "        '''\n",
    "        if self.generator: \n",
    "            return self.generator \n",
    "        \n",
    "        self.generator = Sequential() \n",
    "        dropout = 0.4 \n",
    "        depth = 64 * 16 \n",
    "        dim = 3 \n",
    "        \n",
    "        self.generator.add(Dense(dim*dim*depth, input_dim=self.shape))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        self.generator.add(Reshape((dim, dim, depth)))\n",
    "        self.generator.add(Dropout(dropout))\n",
    "        \n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        \n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        \n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        \n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        \n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        \n",
    "        # Get back to 96*96 Flat list \n",
    "        self.generator.add(Dense(self.shape))\n",
    "        self.generator.add(Activation('sigmoid'))\n",
    "        self.generator.summary()\n",
    "        return self.generator\n",
    "    \n",
    "    def build_dm(self): \n",
    "        if self.discriminator_model: \n",
    "            return self.discriminator_model \n",
    "        \n",
    "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "        self.discriminator_model = Sequential()\n",
    "        self.discriminator_model.add(self.discriminate())\n",
    "        self.discriminator_model.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        \n",
    "        return self.discriminator_model\n",
    "    \n",
    "    def build_am(self): \n",
    "        if self.adversary_model: \n",
    "            return self.adversary_model \n",
    "        \n",
    "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "        self.adversary_model = Sequential()\n",
    "        self.adversary_model.add(self.generate())\n",
    "        self.adversary_model.add(self.discriminate())\n",
    "        self.adversary_model.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        \n",
    "        return self.adversary_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing pokemon from /Users/rchatrath/workspace/phylo/images/regular/\n",
      "Vector iteration 0\n",
      "Vector iteration 100\n",
      "Vector iteration 200\n",
      "Vector iteration 300\n",
      "Vector iteration 400\n",
      "Vector iteration 500\n",
      "Vector iteration 600\n",
      "Done vectorizing\n",
      "Vectorizing pokemon from /Users/rchatrath/workspace/phylo/images/shiny/\n",
      "Vector iteration 0\n"
     ]
    }
   ],
   "source": [
    "pokemon = ph.vectorize_pokemon(ph.REGULAR_POKEMON_PATH) + ph.vectorize_pokemon(ph.SHINY_POKEMON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Manager(object): \n",
    "    \n",
    "    def __init__(self): \n",
    "#         self.pokemon = ph.vectorize_pokemon(ph.REGULAR_POKEMON_PATH) + ph.vectorize_pokemon(ph.SHINY_POKEMON_PATH)\n",
    "        self.pokemon = pokemon \n",
    "        self.GAN = GAN() \n",
    "        self.discriminator = self.GAN.build_dm() \n",
    "        self.adversarial_model = self.GAN.build_am() \n",
    "        self.generator = self.GAN.generate() \n",
    "        \n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0): \n",
    "        \n",
    "        for i in range(train_steps): \n",
    "            images_train = np.random.choice(self.pokemon, batch_size % len(self.pokemon))\n",
    "            noise = np.asarray([ph.generate_random() for i in range(batch_size)])\n",
    "            fake_images = self.generator.predict(noise)\n",
    "            X = np.concatenate(images_train, fake_images) \n",
    "            Y = np.ones([2*batch_size, 1])\n",
    "            Y[batch_size:, :] = 0\n",
    "            d_loss = self.discriminator.train_on_batch(X, Y)\n",
    "            \n",
    "            Y = np.ones([batch_size, 1])\n",
    "            noise = np.asarray([ph.generate_random() for i in range(batch_size)])\n",
    "            a_loss = self.adversarial_model.train_on_batch(noise, y)\n",
    "            \n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "            \n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval==0:\n",
    "                    self.save_image(save2File=True)\n",
    "            \n",
    "    def save_image(save2File=False, samples=16, fake=True): \n",
    "        if fake: \n",
    "            noise = np.asarray([ph.generate_random() for i in range(samples)])\n",
    "            images = self.generator.predict(noise)\n",
    "            cnt = 0 \n",
    "            for img in images: \n",
    "                ph.save_image(img, \"fake_img_{}.png\".format(cnt))\n",
    "                cnt += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    manager = Manager() \n",
    "    manager.train(train_steps=5, batch_size=10, save_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
