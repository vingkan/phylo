{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import phylo as ph \n",
    "\n",
    "import tensorflow \n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object): \n",
    "    \n",
    "    def __init__(self): \n",
    "        self.shape = ph.M ** 2 \n",
    "        self.discriminator = None # Discriminator \n",
    "        self.generator = None # Shareholder value generator\n",
    "        self.adversary_model = None # Adversarial Model \n",
    "        self.discriminator_model = None # Discriminator Model \n",
    "    \n",
    "    def discriminate(self): \n",
    "        '''\n",
    "        Discriminator that transforms 96*96 flat list to a source of truth \n",
    "        '''\n",
    "        if self.discriminator: \n",
    "            return self.discriminator\n",
    "        \n",
    "        self.discriminator = Sequential() \n",
    "        depth = 64 \n",
    "        dropout = 0.4 \n",
    "        channel = 1\n",
    "        \n",
    "        dim = int(self.shape ** .5)\n",
    "        \n",
    "        # In: 96*96 flat list \n",
    "        # Out: 96 x 96 x 1 \n",
    "        self.discriminator.add(Dense(dim*dim*channel, input_dim=self.shape))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Reshape((dim, dim, channel)))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        # In: dim*dim*channel \n",
    "        # Out: 48 x 48 x 1, depth = 64\n",
    "        self.discriminator.add(Conv2D(depth*1, 5, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        self.discriminator.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        self.discriminator.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        self.discriminator.add(Conv2D(depth*8, 5, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        self.discriminator.add(Conv2D(depth*16, 5, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        self.discriminator.add(Conv2D(depth*32, 5, strides=1, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "        \n",
    "        # Flatten back out \n",
    "        self.discriminator.add(Flatten())\n",
    "        self.discriminator.add(Dense(1))\n",
    "        self.discriminator.add(Activation('sigmoid'))\n",
    "        self.discriminator.summary()\n",
    "        return self.discriminator\n",
    "\n",
    "    def generate(self): \n",
    "        '''\n",
    "        Generator that takes random noise and produces an image from it \n",
    "        '''\n",
    "        if self.generator: \n",
    "            return self.generator \n",
    "        \n",
    "        self.generator = Sequential() \n",
    "        dropout = 0.4 \n",
    "        depth = 64 * 16 \n",
    "        dim = 3 \n",
    "        \n",
    "        self.generator.add(Dense(dim*dim*depth, input_dim=self.shape))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        self.generator.add(Reshape((dim, dim, depth)))\n",
    "        self.generator.add(Dropout(dropout))\n",
    "        \n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        \n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        \n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        \n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        \n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        \n",
    "        # Get back to 96*96 Flat list \n",
    "        self.generator.add(Dense(self.shape))\n",
    "        self.generator.add(Activation('sigmoid'))\n",
    "        self.generator.summary()\n",
    "        return self.generator\n",
    "    \n",
    "    def build_dm(self): \n",
    "        if self.discriminator_model: \n",
    "            return self.discriminator_model \n",
    "        \n",
    "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "        self.discriminator_model = Sequential()\n",
    "        self.discriminator_model.add(self.discriminate())\n",
    "        self.discriminator_model.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        \n",
    "        return self.discriminator_model\n",
    "    \n",
    "    def build_am(self): \n",
    "        if self.adversary_model: \n",
    "            return self.adversary_model \n",
    "        \n",
    "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "        self.adversary_model = Sequential()\n",
    "        self.adversary_model.add(self.generate())\n",
    "        self.adversary_model.add(self.discriminate())\n",
    "        self.adversary_model.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        \n",
    "        return self.adversary_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing pokemon from /Users/rchatrath/workspace/phylo/images/regular/\n",
      "Vector iteration 0\n",
      "Vector iteration 100\n",
      "Vector iteration 200\n",
      "Vector iteration 300\n",
      "Vector iteration 400\n",
      "Vector iteration 500\n",
      "Vector iteration 600\n",
      "Done vectorizing\n",
      "Vectorizing pokemon from /Users/rchatrath/workspace/phylo/images/shiny/\n",
      "Vector iteration 0\n",
      "Vector iteration 100\n",
      "Vector iteration 200\n",
      "Vector iteration 300\n",
      "Vector iteration 400\n",
      "Vector iteration 500\n",
      "Vector iteration 600\n",
      "Done vectorizing\n"
     ]
    }
   ],
   "source": [
    "pokemon = ph.vectorize_pokemon(ph.REGULAR_POKEMON_PATH) + ph.vectorize_pokemon(ph.SHINY_POKEMON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Manager(object): \n",
    "    \n",
    "    def __init__(self): \n",
    "#         self.pokemon = ph.vectorize_pokemon(ph.REGULAR_POKEMON_PATH) + ph.vectorize_pokemon(ph.SHINY_POKEMON_PATH)\n",
    "        self.pokemon = pokemon \n",
    "        self.GAN = GAN() \n",
    "        self.discriminator = self.GAN.build_dm() \n",
    "        self.adversarial_model = self.GAN.build_am() \n",
    "        self.generator = self.GAN.generate() \n",
    "        \n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0): \n",
    "        \n",
    "        for i in range(train_steps): \n",
    "            images_train = np.random.choice(self.pokemon, batch_size % len(self.pokemon))\n",
    "            noise = np.asarray([ph.generate_random() for i in range(batch_size)])\n",
    "            fake_images = self.generator.predict(noise)\n",
    "            X = np.concatenate(images_train, fake_images) \n",
    "            Y = np.ones([2*batch_size, 1])\n",
    "            Y[batch_size:, :] = 0\n",
    "            d_loss = self.discriminator.train_on_batch(X, Y)\n",
    "            \n",
    "            Y = np.ones([batch_size, 1])\n",
    "            noise = np.asarray([ph.generate_random() for i in range(batch_size)])\n",
    "            a_loss = self.adversarial_model.train_on_batch(noise, y)\n",
    "            \n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "            \n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval==0:\n",
    "                    self.save_image(save2File=True)\n",
    "            \n",
    "    def save_image(save2File=False, samples=16, fake=True): \n",
    "        if fake: \n",
    "            noise = np.asarray([ph.generate_random() for i in range(samples)])\n",
    "            images = self.generator.predict(noise)\n",
    "            cnt = 0 \n",
    "            for img in images: \n",
    "                ph.save_image(img, \"fake_img_{}.png\".format(cnt))\n",
    "                cnt += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 9216)              84943872  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 96, 96, 1)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 96, 96, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 1024)        13108224  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 2048)        52430848  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 3, 3, 2048)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3, 3, 2048)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 18433     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 154,804,737\n",
      "Trainable params: 154,804,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 9216)              84943872  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9216)              36864     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 6, 6, 512)         13107712  \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 12, 12, 512)       6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 24, 24, 512)       6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 48, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 48, 48, 512)       6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 48, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 48, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 96, 96, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 96, 96, 512)       6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 96, 96, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 96, 96, 512)       0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 96, 96, 9216)      4727808   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 96, 96, 9216)      0         \n",
      "=================================================================\n",
      "Total params: 129,042,944\n",
      "Trainable params: 129,019,392\n",
      "Non-trainable params: 23,552\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8512d3033ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f5f3ca154390>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_am\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-bf415e4b3f16>\u001b[0m in \u001b[0;36mbuild_am\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversary_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversary_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversary_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         self.adversary_model.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n\u001b[1;32m    134\u001b[0m             metrics=['accuracy'])\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m    777\u001b[0m                         input_shapes = unpack_singleton(\n\u001b[1;32m    778\u001b[0m                             [x._keras_shape for x in computed_tensors])\n\u001b[0;32m--> 779\u001b[0;31m                         \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                         uses_learning_phase = any(\n\u001b[1;32m    781\u001b[0m                             [x._uses_learning_phase for x in computed_tensors])\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;31m# input shape known? then we can compute the output shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             return (input_shape[0],) + self._fix_unknown_dimension(\n\u001b[0;32m--> 398\u001b[0;31m                 input_shape[1:], self.target_shape)\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m_fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    manager = Manager() \n",
    "    manager.train(train_steps=1, batch_size=10, save_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
